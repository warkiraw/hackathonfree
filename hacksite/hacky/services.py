import os
import logging
import google.generativeai as genai
import PyPDF2
import aiohttp
from bs4 import BeautifulSoup
import chardet
import re
from google.generativeai import GenerativeModel
import requests
from asgiref.sync import sync_to_async
import json
from typing import List, Dict, Optional, Any
import google.generativeai as genai
from django.conf import settings
from django.db.models import Q
import json
from django.core.cache import cache
import hashlib
from .models import Resume

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API –∫–ª—é—á–µ–π
GOOGLE_API_KEY = 'AIzaSyC6gyL0t2vzDVNijIMbf1VL-igqPw-PsY4'
SERPER_API_KEY = '2acc6a32f0a821eb77ef33a98134cdc6b8830168'

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini
genai.configure(api_key=GOOGLE_API_KEY)
model = GenerativeModel('gemini-pro')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_cache_key(query: str, filters: Dict[str, Any]) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
    cache_data = f"{query}:{sorted(filters.items())}"
    return f"search_results:{hashlib.md5(cache_data.encode()).hexdigest()}"

def get_analysis_cache_key(query: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–∞"""
    return f"query_analysis:{hashlib.md5(query.encode()).hexdigest()}"

def analyze_search_query(query: str) -> Dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é Gemini"""
    cache_key = get_analysis_cache_key(query)
    cached_result = cache.get(cache_key)
    
    if cached_result:
        return cached_result
        
    try:
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –≤–µ—Ä–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON:
        –ó–∞–ø—Ä–æ—Å: {query}
        
        –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
        {{
            "position": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏",
            "required_skills": ["–Ω–∞–≤—ã–∫1", "–Ω–∞–≤—ã–∫2"],
            "similar_positions": ["–ø–æ—Ö–æ–∂–∞—è –ø–æ–∑–∏—Ü–∏—è1", "–ø–æ—Ö–æ–∂–∞—è –ø–æ–∑–∏—Ü–∏—è2"],
            "keywords": ["–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ1", "–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ2"]
        }}
        """
        
        response = model.generate_content(prompt)
        result = json.loads(response.text)
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        cache.set(cache_key, result, timeout=3600)
        return result
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return {}

def calculate_candidate_relevance(candidate: Resume, search_criteria: Dict) -> Dict[str, Any]:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
    try:
        relevance_score = 0
        matching_skills = []
        missing_skills = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–∑–∏—Ü–∏–∏
        if candidate.recommended_positions:
            try:
                recommended = json.loads(candidate.recommended_positions)
                search_position = search_criteria['position'].lower()
                similar_positions = [pos.lower() for pos in search_criteria.get('similar_positions', [])]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –ø–æ–∑–∏—Ü–∏—é
                for position in recommended:
                    position_title = position['position'].lower()
                    
                    # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    if search_position in position_title:
                        relevance_score = position['match_percentage']
                        break
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–∑–∏—Ü–∏–π
                    for similar in similar_positions:
                        if similar in position_title:
                            relevance_score = max(relevance_score, position['match_percentage'] * 0.9)
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    keywords = [kw.lower() for kw in search_criteria.get('keywords', [])]
                    for keyword in keywords:
                        if keyword in position_title:
                            relevance_score = max(relevance_score, position['match_percentage'] * 0.8)
            
            except json.JSONDecodeError:
                # –ï—Å–ª–∏ recommended_positions –Ω–µ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ, –ø—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å –ø–æ —Ç–µ–∫—Å—Ç—É
                text = candidate.recommended_positions.lower()
                if search_criteria['position'].lower() in text:
                    relevance_score = 80
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–≤—ã–∫–∏
        candidate_skills = set()
        if candidate.technical_skills:
            candidate_skills.update(s.strip().lower() for s in candidate.technical_skills.split(','))
        if candidate.soft_skills:
            candidate_skills.update(s.strip().lower() for s in candidate.soft_skills.split(','))
        
        required_skills = set(s.strip().lower() for s in search_criteria.get('required_skills', []))
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –Ω–∞–≤—ã–∫–∏
        for skill in required_skills:
            if skill in candidate_skills:
                matching_skills.append(skill)
                relevance_score += 5  # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å –Ω–∞–≤—ã–∫–æ–≤
            else:
                missing_skills.append(skill)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
        if candidate.work_experience and search_criteria['position'].lower() in candidate.work_experience.lower():
            relevance_score += 10
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫—É
        relevance_score = min(100, relevance_score)
        
        return {
            'relevance_score': relevance_score,
            'matching_skills': matching_skills,
            'missing_skills': missing_skills
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {e}")
        return {
            'relevance_score': 0,
            'matching_skills': [],
            'missing_skills': []
        }

def search_candidates(query: str, filters: Dict[str, Any], page: int = 1, per_page: int = 10) -> Dict[str, Any]:
    """–ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
    try:
        logger.info(f"–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: {query}")
        logger.info(f"–§–∏–ª—å—Ç—Ä—ã: {filters}")
        
        search_criteria = analyze_search_query(query)
        logger.info(f"–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞: {search_criteria}")
        
        candidates = Resume.objects.all()
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        if filters.get('min_rating'):
            candidates = candidates.filter(rating__gte=filters['min_rating'])
        if filters.get('location'):
            candidates = candidates.filter(location__icontains=filters['location'])
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {candidates.count()}")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        results = []
        for candidate in candidates:
            relevance = calculate_candidate_relevance(candidate, search_criteria)
            logger.info(f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ {candidate.id}: {relevance}")
            
            if relevance.get('relevance_score', 0) >= filters.get('min_relevance', 0):
                results.append({
                    'candidate': candidate,
                    'relevance': relevance
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results.sort(key=lambda x: x['relevance']['relevance_score'], reverse=True)
        
        return {
            'total': len(results),
            'results': results[(page-1)*per_page:page*per_page]
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {e}")
        return {'total': 0, 'results': []}

def search_google(query):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–∏—Å–∫–∞ –≤ Google"""
    url = "https://google.serper.dev/search"
    headers = {
        'X-API-KEY': SERPER_API_KEY,
        'Content-Type': 'application/json'
    }
    payload = {
        'q': query,
        'num': 10
    }
    try:
        response = requests.post(url, headers=headers, json=payload)
        results = response.json()
        return results.get('organic', [])
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
        return []

def get_page_content(url):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    try:
        response = requests.get(url)
        if response.status_code == 200:
            content = response.content
            try:
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                try:
                    return content.decode('utf-8')
                except UnicodeDecodeError:
                    try:
                        return content.decode('cp1251')
                    except UnicodeDecodeError:
                        try:
                            return content.decode('latin1')
                        except UnicodeDecodeError:
                            detected = chardet.detect(content)
                            if detected['encoding']:
                                return content.decode(detected['encoding'])
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
                return content.decode('utf-8', errors='ignore')
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        return None

def extract_text_from_pdf(file_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
    try:
        with open(file_path, 'rb') as pdf_file:
            reader = PyPDF2.PdfReader(pdf_file)
            text = ''
            for page in reader.pages:
                text += page.extract_text() + '\n'
        return text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF: {e}")
        return None

def analyze_resume(resume):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ"""
    try:
        resume_text = extract_text_from_pdf(resume.file.path)
        if not resume_text:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF")

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        resume_analysis = process_with_chatgpt(resume_text, [], "HR")
        if not resume_analysis:
            raise Exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å –∏ –∫–∞—Ä—å–µ—Ä—É
        style_analysis = analyze_resume_style(resume_text)
        career_analysis = analyze_career_progression(resume_analysis)
        
        # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        final_analysis = create_final_analysis(
            resume_analysis=resume_analysis,
            org_analyses=[],  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, —Ç–∞–∫ –∫–∞–∫ –∞–Ω–∞–ª–∏–∑ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω
            style_analysis=style_analysis,
            career_analysis=career_analysis
        )

        if not final_analysis:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑")

        return final_analysis

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∑—é–º–µ: {str(e)}")
        return None

def analyze_organization(org_name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é"""
    try:
        search_results = search_google(f"{org_name} –æ—Ç–∑—ã–≤—ã —Ä–µ–π—Ç–∏–Ω–≥")
        texts = []
        for result in search_results[:3]:
            if content := get_page_content(result.get('link', '')):
                texts.append(content)
        
        combined_text = "\n".join(texts)
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é {org_name} –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:
{combined_text}

–ü—Ä–µ–¥–æ—Å—Ç–≤—å –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
1. –£—Ä–æ–≤–µ–Ω—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–≤—ã—Å–æ–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–Ω–∏–∑–∫–∏–π)
2. –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤/—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
3. –†–µ–π—Ç–∏–Ω–≥ (1-10)
4. –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"""

        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ {org_name}: {e}")
        return None

def analyze_organization_details(org_name, org_type):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"""
    try:
        query = f"{org_name} "
        if "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç" in org_name.lower() or "–∏–Ω—Å—Ç–∏—Ç—É—Ç" in org_name.lower():
            query += "–æ—Ç–∑—ã–≤—ã –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤ —Ä–µ–π—Ç–∏–Ω–≥ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"
        else:
            query += "–æ—Ç–∑—ã–≤—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —É—Å–ª–æ–≤–∏—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–µ–∫—Ç—ã"

        search_results = search_google(query)
        texts = []
        for result in search_results[:3]:
            if content := get_page_content(result.get('link', '')):
                texts.append(content)
        
        combined_text = "\n".join(texts)
        
        if "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç" in org_name.lower() or "–∏–Ω—Å—Ç–∏—Ç—É—Ç" in org_name.lower():
            prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É—á–µ–±–Ω–æ–º –∑–∞–≤–µ–¥–µ–Ω–∏–∏ {org_name}:
{combined_text}

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑:
1. –£—Ä–æ–≤–µ–Ω—å —É—á–µ–±–Ω–æ–≥–æ –∑–∞–≤–µ–¥–µ–Ω–∏—è (–≤—ã—Å–æ–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–Ω–∏–∑–∫–∏–π)
2. –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤
3. –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã
4. –†–µ–π—Ç–∏–Ω–≥ –≤—É–∑–∞ (1-10)"""
        else:
            prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏ {org_name}:
{combined_text}

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑:
1. –£—Ä–æ–≤–µ–Ω—å –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ —Ä—ã–Ω–∫–µ (–≤—ã—Å–æ–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–Ω–∏–∫–∏–π)
2. –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
3. –¢—Ä–µ–±—É–µ–º—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
4. –†–µ–π—Ç–∏–Ω–≥ –∫–∞–∫ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è (1-10)"""

        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ {org_name}: {e}")
        return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ {org_name}"

def analyze_resume_style(resume_text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç —Å—Ç–∏–ª—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è —Ä–µ–∑—é–º–µ"""
    try:
        prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∏–ª—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è —Ä–µ–∑—é–º–µ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä —á–µ–ª–æ–≤–µ–∫–∞. –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞:

1. –°–¢–ò–õ–¨ –ö–û–ú–ú–£–ù–ò–ö–ê–¶–ò–ò
- –§–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å/–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –æ–∫—Ä–∞—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞

2. –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–´–ô –ò–ù–¢–ï–õ–õ–ï–ö–¢
- –°–ø–æ—Å–æ–± –æ–ø–∏—Å–∞–Ω–∏—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π
- –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∫–æ–ª–ª–µ–≥–∞–º/—Ä—É–∫–æ–≤–æ—Å—Ç–≤—É
- –£–º–µ–Ω–∏–µ –ø—Ä–µ–∑–µ–Ω—Ç–æ–≤–∞—Ç—å —Å–≤–æ–π –æ–ø—ã—Ç
- –£—Ä–æ–≤–µ–Ω—å —Å–∞–º–æ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏

3. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–ê–Ø –ó–†–ï–õ–û–°–¢–¨
- –ì–ª—É–±–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è –æ–ø—ã—Ç–∞
- –ê–∫—Ü–µ–Ω—Ç—ã –≤ –∫–∞—Ä—å–µ—Ä–Ω—ã—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è—Ö
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤
- –£—Ä–æ–≤–µ–Ω—å –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏

4. –ú–û–¢–ò–í–ê–¶–ò–Ø –ò –°–¢–†–ï–ú–õ–ï–ù–ò–Ø
- –£–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Å–∞–º–æ–∞–∑–≤–∏—Ç–∏–µ
- –ö–∞—Ä—å–µ—Ä–Ω—ã–µ –∞–º–±–∏—Ü–∏–∏
- –ü—Ä–æ—Ñ—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã
- –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º

–°—Ñ–æ—Ä–º–∏—Ä—É–π —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏, –≤–∫–ª—é—á–∞—è:
1. –¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∏–ª—å —Ä–∞–±–æ—Ç—ã
2. –£—Ä–æ–≤–µ–Ω—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞
3. –ü–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é –∑–∞–¥–∞—á
4. –ö–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
5. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
6. –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–æ–Ω—ã —Ä–æ—Å—Ç–∞"""

        response = model.generate_content(prompt + "\n\n–¢–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ:\n" + resume_text)
        return response.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–∏–ª—è —Ä–µ–∑—é–º–µ: {e}")
        return None

def analyze_career_progression(resume_analysis):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—Ä—å–µ—Ä–Ω—É—é –ø—Ä–æ–≥—Ä–µ—Å—Å–∏—é"""
    try:
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞—Ä—å–µ—Ä–Ω—ã–π –ø—É—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—é–º–µ(–≤—Å–µ –ø—É–Ω–∫—Ç—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω—ã):

{resume_analysis}

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∞–Ω–∞–ª–∏–∑ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:

1. –ö–ê–†–¨–ï–†–ù–ê–Ø –ü–†–û–ì–†–ï–°–°–ò–Ø
- –°–∫–æ—Ä–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ (–±—ã—Å—Ç—Ä–∞—è/—Å—Ä–µ–¥–Ω—è—è/–º–µ–¥–ª–µ–Ω–Ω–∞—è)
- –ö–∞—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (–ø–æ–≤—ã—à–µ–Ω–∏—è/–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—å–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã)
- –õ–æ–≥–∏–∫–∞ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ –ø—É—Ç–∏

2. –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–¨
- –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã
- –ü—Ä–∏—á–∏–Ω—ã —Å–º–µ–Ω—ã —Ä–∞–±–æ—Ç—ã (–µ—Å–ª–∏ –≤–∏–¥–Ω—ã)
- –û—Ü–µ–Ω–∫–∞ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏

3. –¢–ï–ù–î–ï–ù–¶–ò–ò
- –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–≤–∏—Ç–∏—è –∫–∞—å–µ—Ä—ã
- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é

–°–¥–µ–ª–∞–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –¥–∏–Ω–∞–º–∏–∫–µ —Ä–æ—Å—Ç–∞ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏."""

        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–∞—Ä—å–µ—Ä–Ω–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–∏: {e}")
        return None

def calculate_rating(basic_info, skills, experience, style_analysis, career_analysis):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    try:
        score = 0
        
        # –û—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–º–∞–∫—Å–∏–º—É–º 15 –±–∞–ª–ª–æ–≤)
        if isinstance(basic_info, dict):
            if basic_info.get('full_name'): score += 5
            if basic_info.get('age'): score += 5
            if basic_info.get('location'): score += 5
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ (–º–∞–∫—Å–∏–º—É–º 45 –±–∞–ª–ª–æ–≤)
        if isinstance(skills, dict):
            technical_skills_count = len(skills.get('technical', []))
            soft_skills_count = len(skills.get('soft', []))
            score += min(technical_skills_count * 3, 30)  # –ú–∞–∫—Å–∏–º—É–º 30 –±–∞–ª–ª–æ–≤ –∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏
            score += min(soft_skills_count * 3, 15)  # –ú–∞–∫—Å–∏–º—É–º 15 –±–∞–ª–ª–æ–≤ –∑–∞ soft skills
        
        # –û—Ü–µ–Ω–∫–∞ –æ–ø—ã—Ç–∞ (–º–∞–∫—Å–∏–º—É–º 25 –±–∞–ª–ª–æ–≤)
        if isinstance(experience, list):
            experience_years = 0
            for exp in experience:
                if isinstance(exp, dict) and exp.get('period'):
                    # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç –ª–µ—Ç –∏–∑ –ø–µ—Ä–∏–æ–¥–∞
                    period = exp['period'].lower()
                    if '–≥–æ–¥' in period or '–ª–µ—Ç' in period:
                        try:
                            years = int(''.join(filter(str.isdigit, period.split()[0])))
                            experience_years += years
                        except:
                            pass
            score += min(experience_years * 2, 25)
        
        # –û—Ü–µ–Ω–∫–∞ —Å—Ç–∏–ª—è –∏ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞ (–º–∞–∫—Å–∏–º—É–º 15 –±–∞–ª–ª–æ–≤)
        if style_analysis: score += 10
        if career_analysis: score += 5
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
        final_score = min(max(score, 0), 100)
        
        logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥: {final_score}")
        return final_score

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ä–µ–π—Ç–∏–Ω–≥–∞: {e}")
        return 0

def create_final_analysis(resume_analysis, org_analyses, style_analysis, career_analysis):
    """–°–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ"""
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        basic_info = extract_basic_info(resume_analysis) or {}
        skills = extract_skills_from_analysis(resume_analysis) or {'technical': [], 'soft': []}
        experience = extract_work_experience(resume_analysis) or []
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥
        rating_score = calculate_rating(
            basic_info=basic_info,
            skills=skills,
            experience=experience,
            style_analysis=style_analysis,
            career_analysis=career_analysis
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        final_data = {
            'basic_info': {
                'full_name': basic_info.get('full_name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
                'age': basic_info.get('age', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
                'location': basic_info.get('location', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
            },
            'education': basic_info.get('education', []),
            'work_experience': experience,
            'skills': {
                'technical': skills.get('technical', []),
                'soft': skills.get('soft', [])
            },
            'career_progression': {
                'growth_speed': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'transitions': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'path_logic': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'
            },
            'rating': {
                'score': rating_score,
                'advantages': extract_advantages(resume_analysis) or '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'growth_zones': extract_growth_zones(resume_analysis) or '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'recommendations': extract_recommendations(resume_analysis) or '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'risks': extract_risks(resume_analysis) or '–ù–µ —É–∫–∞–∑–∞–Ω–æ'
            }
        }

        return json.dumps(final_data, ensure_ascii=False)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None

def format_data_for_admin(data):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∞–¥–º–∏–Ω–∫–µ"""
    try:
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        education = data.get('education', [])
        if isinstance(education, list):
            education_formatted = "\n".join([
                f"üéì {edu['institution']}\n"
                f"üìö {edu['degree']}\n"
                f"üìÖ {edu['period']}\n"
                for edu in education
            ])
        else:
            education_formatted = education

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
        work_experience = data.get('work_experience', [])
        if isinstance(work_experience, list):
            work_formatted = "\n".join([
                f"üëî {work['position']}\n"
                f"üè¢ {work['company']}\n"
                f"üìÖ {work['period']}\n"
                f"üìã {', '.join(work['responsibilities'])}\n"
                for work in work_experience
            ])
        else:
            work_formatted = work_experience

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–≤—ã–∫–∏
        skills = data.get('skills', {})
        technical_skills = "\n".join([f"üíª {skill}" for skill in skills.get('technical', [])])
        soft_skills = "\n".join([f"ü§ù {skill}" for skill in skills.get('soft', [])])

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Å—Ç–∏–∂–µ–Ω–∏—è
        achievements = data.get('achievements', [])
        if isinstance(achievements, list):
            achievements_formatted = "\n".join([
                f"üèÜ {ach['category']}: {ach['description']}"
                for ach in achievements if isinstance(ach, dict)
            ])
        else:
            achievements_formatted = achievements

        return {
            'full_name': data['basic_info']['full_name'],
            'age': data['basic_info']['age'],
            'location': data['basic_info']['location'],
            'education': education_formatted,
            'work_experience': work_formatted,
            'career_progression': (
                f"üìà –°–∫–æ—Ä–æ—Å—Ç—å —Ä–æ—Å—Ç–∞: {data['career_progression']['growth_speed']}\n"
                f"üîÑ –ü–µ—Ä–µ—Ö–æ–¥—ã: {data['career_progression']['transitions']}\n"
                f"üõ£Ô∏è –õ–æ–≥–∏–∫–∞ –ø—É—Ç–∏: {data['career_progression']['path_logic']}"
            ),
            'technical_skills': technical_skills,
            'soft_skills': soft_skills,
            'personality_profile': (
                f"üë§ –¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏: {data['personality_profile']['type']}\n"
                f"üß† –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç: {data['personality_profile']['emotional_intelligence']}\n"
                f"üí¨ –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è: {data['personality_profile']['communication']}\n"
                f"üéØ –†–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á: {data['personality_profile']['problem_solving']}"
            ),
            'achievements': achievements_formatted,
            'rating': data['rating']['score'],
            'advantages': "\n".join([f"‚úÖ {adv}" for adv in data['rating']['advantages']]),
            'growth_zones': "\n".join([f"üìà {zone}" for zone in data['rating']['growth_zones']]),
            'recommendations': "\n".join([f"üí° {rec}" for rec in data['rating']['recommendations']]),
            'risks': "\n".join([f"‚ö†Ô∏è {risk}" for risk in data['rating']['risks']])
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return {}

def extract_organizations_from_analysis(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        organizations = []
        
        # –ò—â–µ–º —É—á–µ–±–Ω—ã–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è
        education_section = re.search(r'\*\*2\.\s*–û–ë–†–ê–ó–û–í–ê–ù–ò–ï\*\*\n(.*?)(?=\*\*3\.)', analysis_text, re.DOTALL)
        if education_section:
            edu_text = education_section.group(1)
            edu_orgs = re.findall(r'-\s*(.*?)(?:\(|,|\d|$)', edu_text)
            organizations.extend([org.strip() for org in edu_orgs if org.strip()])

        # –ò—â–º –º–µ—Å—Ç–∞ —Ä–∞–±–æ—Ç—ã
        work_section = re.search(r'\*\*3\.\s*–ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –û–ü–´–¢\*\*\n(.*?)(?=\*\*4\.)', analysis_text, re.DOTALL)
        if work_section:
            work_text = work_section.group(1)
            work_orgs = re.findall(r'(?:–¢–û–û|–ê–û)\s*[¬´"]([^¬ª"]+)[¬ª"]|(?:–§–∏–ª–∏–∞–ª|–ö–æ–º–ø–∞–Ω–∏—è)\s+([^,\n]+)', work_text)
            for matches in work_orgs:
                org = next((match for match in matches if match), None)
                if org:
                    organizations.append(org.strip())

        return list(set(organizations))  # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π: {e}")
        return []

def get_brief_analysis(full_analysis):
    """–ü–æ–ª—É—á–∞–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑"""
    try:
        prompt = f"–°–æ–∫—Ä–∞—Ç–∏ —Å–ª–µ–¥—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ 2-3 –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:\n\n{full_analysis}"
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."

def process_with_chatgpt(text, history, role):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é ChatGPT"""
    try:
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—é–º–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:

1. –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
–§–ò–û: 
–í–æ–∑—Ä–∞—Å—Ç:
–õ–æ–∫–∞—Ü–∏—è:

2. –û–ë–†–ê–ó–û–í–ê–ù–ò–ï
(–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è)

3. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –û–ü–´–¢
(–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã)

4. –ö–ê–†–¨–ï–†–ù–ê–Ø –ü–†–û–ì–†–ï–°–°–ò–Ø
(–∞–Ω–∞–ª–∏–∑ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞)

5. –ö–õ–Æ–ß–ï–í–´–ï –ù–ê–í–´–ö–ò
–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ: (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
Soft skills: (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)

6. –õ–ò–ß–ù–û–°–¢–ù–´–ô –ü–†–û–§–ò–õ–¨
(–∞–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–Ω—ã—Ö –∫–∞—á–µ—Å—Ç–≤)

7. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ï –î–û–°–¢–ò–ñ–ï–ù–ò–Ø
(–∫–ª—é—á–µ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è)

8. –ú–û–¢–ò–í–ê–¶–ò–Ø –ò –°–¢–†–ï–ú–õ–ï–ù–ò–Ø
(–∞–Ω–∞–ª–∏–∑ –º–æ—Ç–∏–≤–∞—Ü–∏–∏)

9. –ö–û–†–ü–û–†–ê–¢–ò–í–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨
(–æ—Ü–µ–Ω–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)

10. –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ü–û–ó–ò–¶–ò–ò
(—Å–ø–∏—Å–æ–∫ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ–∑–∏—Ü–∏–π)

11. –ö–ê–†–¨–ï–†–ù–´–ô –ü–õ–ê–ù
(—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é)

12. –û–ë–©–ò–ô –†–ï–ô–¢–ò–ù–ì
(–æ—Ü–µ–Ω–∫–∞ –≤ –±–∞–ª–ª–∞—Ö –æ—Ç 0 –¥–æ 100)
–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
–ó–æ–Ω—ã —Ä–æ—Å—Ç–∞:
–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏:

–¢–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ:
{text}"""

        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {e}")
        return None

def search_place_info(place_name):
    """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ—Å—Ç–µ"""
    query = f"{place_name} –æ—Ç–∑—ã–≤—ã, —Ä–µ–π—Ç–∏–Ω–≥, –Ω–æ–≤–æ—Å—Ç–∏"
    return search_google(query)

def extract_skills_from_analysis(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–≤—ã–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if isinstance(analysis_text, str):
            skills_section = re.search(r'5\. –ö–õ–Æ–ß–ï–í–´–ï –ù–ê–í–´–ö–ò(.*?)(?=\d+\.|$)', analysis_text, re.DOTALL)
            if skills_section:
                skills_text = skills_section.group(1)
                technical = re.search(r'–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ:(.*?)(?=Soft skills:|$)', skills_text, re.DOTALL)
                soft = re.search(r'Soft skills:(.*?)(?=\d+\.|$)', skills_text, re.DOTALL)
                
                return {
                    'technical': [s.strip() for s in (technical.group(1) if technical else '').split(',') if s.strip()],
                    'soft': [s.strip() for s in (soft.group(1) if soft else '').split(',') if s.strip()]
                }
        return {'technical': [], 'soft': []}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–≤—ã–∫–æ–≤: {e}")
        return {'technical': [], 'soft': []}

def extract_education_info(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏"""
    education_lines = []
    capture = False
    for line in text.split('\n'):
        if "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ:" in line:
            capture = True
        elif capture and line.strip() == "":
            break
        elif capture:
            education_lines.append(line.strip())
    return "\n".join(education_lines)

def generate_recommended_positions(data):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞ –∏ –Ω–∞–≤—ã–∫–æ–≤"""
    try:
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        experience = [work.get('position', '') for work in data.get('work_experience', [])]
        technical_skills = data.get('skills', {}).get('technical', [])
        soft_skills = data.get('skills', {}).get('soft', [])
        industry_experience = data.get('corporate_compatibility', {}).get('experience', [])

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞
        management_positions = sum(1 for pos in experience if any(title in pos.lower() 
            for title in ['–¥–∏—Ä–µ–∫—Ç–æ—Ä', '—Ä–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', '–º–µ–Ω–µ–¥–∂–µ—Ä', '–Ω–∞—á–∞–ª—å–Ω–∏–∫']))
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
        retail_experience = any('—Ä–æ–∑–Ω–∏—á–Ω' in str(exp).lower() for exp in experience + industry_experience)
        sales_experience = any('–ø—Ä–æ–¥–∞' in str(exp).lower() for exp in experience + industry_experience)
        marketing_experience = any('–º–∞—Ä–∫–µ—Ç–∏–Ω–≥' in str(exp).lower() for exp in experience + soft_skills)
        
        recommended_positions = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞  –Ω–∞–≤—ã–∫–æ–≤
        if management_positions >= 2:
            if retail_experience:
                recommended_positions.append({
                    "position": "–î–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é —Ä–æ–∑–Ω–∏—á–Ω–æ–π —Å–µ—Ç–∏",
                    "match_percentage": 90,
                    "reasoning": "–ë–æ–≥–∞—Ç—ã–π –æ–ø—ã—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ —Ä–æ–∑–Ω–∏—á–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ"
                })
            
            if sales_experience:
                recommended_positions.append({
                    "position": "–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä",
                    "match_percentage": 85,
                    "reasoning": "–û–ø—ã—Ç –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏"
                })
                
            recommended_positions.append({
                "position": "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä —Å—Ä–µ–¥–Ω–µ–≥–æ –±–∏–∑–Ω–µ—Å–∞",
                "match_percentage": 80,
                "reasoning": "–û–±—à–∏—Ä–Ω—ã–π —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–π –æ–ø—ã—Ç"
            })

        if marketing_experience:
            recommended_positions.append({
                "position": "–î–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É",
                "match_percentage": 75,
                "reasoning": "–û–ø—ã—Ç –≤ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏"
            })

        if retail_experience:
            recommended_positions.append({
                "position": "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–æ–∑–Ω–∏—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂",
                "match_percentage": 85,
                "reasoning": "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ —Ä–æ–∑–Ω–∏—á–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ"
            })

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–ø—ã—Ç–∞
        latest_position = experience[0] if experience else ""
        if latest_position:
            recommended_positions.append({
                "position": f"Senior {latest_position}",
                "match_percentage": 95,
                "reasoning": "–ü—Ä—è–º–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ —Ç–µ–∫—É—â–µ–π –∫–∞—Ä—å–µ—Ä–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏"
            })

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        recommended_positions.sort(key=lambda x: x['match_percentage'], reverse=True)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ø-5 –ø–æ–∑–∏—Ü–∏–π
        return recommended_positions[:5]

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –ø–æ–∑–∏—Ü–∏–π: {e}")
        return []

def process_analysis_for_admin(analysis_text):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∞–¥–º–∏–Ω–∫–µ"""
    try:
        if not analysis_text:
            return {}

        # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
        try:
            data = json.loads(analysis_text)
            
            # –ï—Å–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –ø—É—Å—Ç—ã–µ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ö
            if not data.get('recommended_positions'):
                data['recommended_positions'] = generate_recommended_positions(data)
            
            formatted_data = format_data_for_admin(data)
            
            # –§—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if data.get('recommended_positions'):
                formatted_data['recommended_positions'] = "\n".join([
                    f"üëî {pos['position']}\n"
                    f"üìä –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {pos['match_percentage']}%\n"
                    f"üí° –ü—Ä–∏—á–∏–Ω–∞: {pos['reasoning']}\n"
                    for pos in data['recommended_positions']
                ])
            
            return formatted_data

        except json.JSONDecodeError:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞")
            return process_analysis_old_method(analysis_text)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –∞–¥–º–∏–Ω–∫–∏: {e}")
        return {}

def process_analysis_old_method(analysis_text):
    """–°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        data = {}
        sections = analysis_text.split('**')
        
        for section in sections:
            section = section.strip()
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if '1. –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø' in section:
                for line in section.split('\n'):
                    if '–§–ò–û:' in line:
                        data['full_name'] = line.split('–§–ò–û:')[1].strip()
                    elif '–í–æ–∑—Ä–∞—Å—Ç:' in line:
                        data['age'] = line.split('–í–æ–∑—Ä–∞—Å—Ç:')[1].strip()
                    elif '–õ–æ–∫–∞—Ü–∏—è:' in line:
                        data['location'] = line.split('–õ–æ–∫–∞—Ü–∏—è:')[1].strip()
            
            # –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            elif '2. –û–ë–†–ê–ó–û–í–ê–ù–ò–ï' in section:
                data['education'] = section.split('2. –û–ë–†–ê–ó–û–í–ê–ù–ò–ï')[1].strip()
            
            # –û–ø—Ç —Ä–∞–±–æ—Ç—ã
            elif '3. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –û–ü–´–¢' in section:
                data['work_experience'] = section.split('3. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –û–ü–´–¢')[1].strip()
            
            # –ö–∞—Ä—å–µ—Ä–Ω–∞—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∏—è
            elif '4. –ö–ê–†–¨–ï–†–ù–ê–Ø –ü–†–û–ì–†–ï–°–°–ò–Ø' in section:
                data['career_progression'] = section.split('4. –ö–ê–†–¨–ï–†–ù–ê–Ø –ü–†–û–ì–†–ï–°–°–ò–Ø')[1].strip()
            
            # –ù–∞–≤—ã–∫–∏
            elif '5. –ö–õ–Æ–ß–ï–í–´–ï –ù–ê–í–´–ö–ò' in section:
                skills_text = section.split('5. –ö–õ–Æ–ß–ï–í–´–ï –ù–ê–í–´–ö–ò')[1]
                technical_skills = []
                soft_skills = []
                
                for line in skills_text.split('\n'):
                    if '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ:' in line:
                        technical_skills = [s.strip() for s in line.split('–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ:')[1].split(',')]
                    elif 'Soft skills:' in line:
                        soft_skills = [s.strip() for s in line.split('Soft skills:')[1].split(',')]
                
                data['technical_skills'] = '\n'.join(technical_skills)
                data['soft_skills'] = '\n'.join(soft_skills)
            
            # –õ–∏—á–Ω–æ—Å—Ç–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
            elif '6. –õ–ò–ß–ù–û–°–¢–ù–´–ô –ü–†–û–§–ò–õ–¨' in section:
                data['personality_profile'] = section.split('6. –õ–ò–ß–ù–û–°–¢–ù–´–ô –ü–†–û–§–ò–õ–¨')[1].strip()
            
            # –î–æ—Å—Ç–∏–∂–µ–Ω–∏—è
            elif '7. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ï –î–û–°–¢–ò–ñ–ï–ù–ò–Ø' in section:
                data['achievements'] = section.split('7. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ï –î–û–°–¢–ò–ñ–ï–ù–ò–Ø')[1].strip()
            
            # –ú–æ—Ç–∏–≤–∞—Ü–∏—è
            elif '8. –ú–û–¢–ò–í–ê–¶–ò–Ø –ò –°–¢–†–ï–ú–õ–ï–ù–ò–Ø' in section:
                data['motivation'] = section.split('8. –ú–û–¢–ò–í–ê–¶–ò–Ø –ò –°–¢–†–ï–ú–õ–ï–ù–ò–Ø')[1].strip()
            
            # –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
            elif '9. –ö–û–†–ü–û–†–ê–¢–ò–í–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨' in section:
                data['corporate_compatibility'] = section.split('9. –ö–û–†–ü–û–†–ê–¢–ò–í–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨')[1].strip()
            
            # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–æ–∑–∏—Ü–∏–∏
            elif '10. –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ü–û–ó–ò–¶–ò–ò' in section:
                data['recommended_positions'] = section.split('10. –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ü–û–ó–ò–¶–ò–ò')[1].strip()
            
            # –ö–∞—Ä—å–µ—Ä–Ω—ã–π –ø–ª–∞–Ω
            elif '11. –ö–ê–†–¨–ï–†–ù–´–ô –ü–õ–ê–ù' in section:
                data['career_plan'] = section.split('11. –ö–ê–†–¨–ï–†–ù–´–ô –ü–õ–ê–ù')[1].strip()
            
            # –†–µ–π—Ç–∏–Ω–≥ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            elif '12. –û–ë–©–ò–ô –†–ï–ô–¢–ò–ù–ì' in section:
                rating_text = section.split('12. –û–ë–©–ò–ô –†–ï–ô–¢–ò–ù–ì')[1]
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                rating_match = re.search(r'(\d+)\s*–±–∞–ª–ª–æ–≤', rating_text)
                if rating_match:
                    data['rating'] = int(rating_match.group(1))
                else:
                    data['rating'] = 0
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏—Å–ø–æ–ª—å–∑—É—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
                advantages_match = re.search(r'–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:(.*?)(?=–ó–æ–Ω—ã —Ä–æ—Å—Ç–∞:|$)', rating_text, re.DOTALL)
                if advantages_match:
                    data['advantages'] = advantages_match.group(1).strip()
                
                growth_zones_match = re.search(r'–ó–æ–Ω—ã —Ä–æ—Å—Ç–∞:(.*?)(?=–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:|$)', rating_text, re.DOTALL)
                if growth_zones_match:
                    data['growth_zones'] = growth_zones_match.group(1).strip()
                
                recommendations_match = re.search(r'–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:(.*?)(?=–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏:|$)', rating_text, re.DOTALL)
                if recommendations_match:
                    data['recommendations'] = recommendations_match.group(1).strip()
                
                risks_match = re.search(r'–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏:(.*?)$', rating_text, re.DOTALL)
                if risks_match:
                    data['risks'] = risks_match.group(1).strip()
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
                data.setdefault('advantages', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                data.setdefault('growth_zones', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                data.setdefault('recommendations', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                data.setdefault('risks', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')

        logger.info(f"–î–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {data}")
        return data
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –º–µ—Ç–æ–¥–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        return {
            'advantages': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'growth_zones': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'recommendations': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'risks': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'rating': 0
        }

def extract_basic_info(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        info = {}
        if isinstance(analysis_text, str):
            # –ü–æ–∏—Å–∫ –§–ò–û
            name_match = re.search(r'–§–ò–û:?\s*([^\n]+)', analysis_text)
            if name_match:
                info['full_name'] = name_match.group(1).strip()
            
            # –ü–æ–∏—Å–∫ –≤–æ–∑—Ä–∞—Å—Ç–∞
            age_match = re.search(r'–í–æ–∑—Ä–∞—Å—Ç:?\s*([^\n]+)', analysis_text)
            if age_match:
                info['age'] = age_match.group(1).strip()
            
            # –ü–æ–∏—Å–∫ –ª–æ–∫–∞—Ü–∏–∏
            location_match = re.search(r'–õ–æ–∫–∞—Ü–∏—è:?\s*([^\n]+)', analysis_text)
            if location_match:
                info['location'] = location_match.group(1).strip()
            
            # –ü–æ–∏—Å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
            education_match = re.search(r'–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ:?\s*([^\n]+(?:\n[^\n]+)*)', analysis_text)
            if education_match:
                info['education'] = education_match.group(1).strip()
        
        return info
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
        return {}

def extract_advantages(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if isinstance(analysis_text, str):
            match = re.search(r'–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:?\s*([^\n]+(?:\n[^\n]+)*?)(?=\n\s*(?:–ó–æ–Ω—ã —Ä–æ—Å—Ç–∞|$))', analysis_text)
            if match:
                return match.group(1).strip()
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤: {e}")
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

def extract_growth_zones(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–æ–Ω—ã —Ä–æ—Å—Ç–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if isinstance(analysis_text, str):
            match = re.search(r'–ó–æ–Ω—ã —Ä–æ—Å—Ç–∞:?\s*([^\n]+(?:\n[^\n]+)*?)(?=\n\s*(?:–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏|$))', analysis_text)
            if match:
                return match.group(1).strip()
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∑–æ–Ω —Ä–æ—Å—Ç–∞: {e}")
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

def extract_recommendations(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if isinstance(analysis_text, str):
            match = re.search(r'–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:?\s*([^\n]+(?:\n[^\n]+)*?)(?=\n\s*(?:–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏|$))', analysis_text)
            if match:
                return match.group(1).strip()
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

def extract_risks(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–∏—Å–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if isinstance(analysis_text, str):
            match = re.search(r'–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏:?\s*([^\n]+(?:\n[^\n]+)*?)(?=\n\s*|$)', analysis_text)
            if match:
                return match.group(1).strip()
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ä–∏—Å–∫–æ–≤: {e}")
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

def extract_personality_info(style_analysis):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∏–ª—è"""
    try:
        if not style_analysis:
            return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ª–∏—á–Ω–æ—Å—Ç–∏
        personality_info = re.search(r'–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏.*?(?=\n\n|\Z)', style_analysis, re.DOTALL)
        if personality_info:
            return personality_info.group(0).strip()
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–∏—á–Ω–æ—Å—Ç–∏: {e}")
        return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

def extract_work_experience(analysis_text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if not isinstance(analysis_text, str):
            return []
        
        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é —Å –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã
        experience_section = re.search(
            r'–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã:?\s*([^\n]+(?:\n[^\n]+)*?)(?=\n\s*(?:[–ê-–Ø]|$))', 
            analysis_text, 
            re.DOTALL
        )
        
        if not experience_section:
            return []

        experience_text = experience_section.group(1).strip()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–µ—Å—Ç–∞ —Ä–∞–±–æ—Ç—ã
        experiences = []
        current_experience = {}
        
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—Ç–∞ —Ä–∞–±–æ—Ç—ã
        experience_patterns = re.finditer(
            r'(?:–ö–æ–º–ø–∞–Ω–∏—è|–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è):\s*([^\n]+)\s*'
            r'(?:–î–æ–ª–∂–Ω–æ—Å—Ç—å|–ü–æ–∑–∏—Ü–∏—è):\s*([^\n]+)\s*'
            r'(?:–ü–µ—Ä–∏–æ–¥|–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã):\s*([^\n]+)\s*'
            r'(?:–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏|–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è)?:?\s*([^\n]+(?:\n(?!\s*(?:–ö–æ–º–ø–∞–Ω–∏—è|–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è)).*)*)',
            experience_text,
            re.DOTALL
        )

        for match in experience_patterns:
            experiences.append({
                'company': match.group(1).strip(),
                'position': match.group(2).strip(),
                'period': match.group(3).strip(),
                'responsibilities': match.group(4).strip().split('\n') if match.group(4) else []
            })

        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –ø–æ —à–∞–±–ª–æ–Ω—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–¥–∏–Ω –æ–ø—ã—Ç
        if not experiences:
            experiences = [{
                'company': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'position': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'period': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                'responsibilities': [line.strip() for line in experience_text.split('\n') if line.strip()]
            }]

        return experiences

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã: {e}")
        return [{
            'company': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'position': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'period': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
            'responsibilities': []
        }]

def extract_career_info(career_analysis):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—Ä—å–µ—Ä–Ω–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–∏"""
    try:
        if not isinstance(career_analysis, str):
            return {
                'growth_speed': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'transitions': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'path_logic': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'progression': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'achievements': []
            }
        
        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é —Å –∫–∞—Ä—å–µ—Ä–Ω–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–µ–π
        career_section = re.search(
            r'4\. –ö–ê–†–¨–ï–†–ù–ê–Ø –ü–†–û–ì–†–ï–°–°–ò–Ø(.*?)(?=\d+\.|$)',
            career_analysis,
            re.DOTALL
        )
        
        if not career_section:
            return {
                'growth_speed': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'transitions': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'path_logic': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'progression': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                'achievements': []
            }

        career_text = career_section.group(1).strip()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –∫–∞—Ä—å–µ—Ä–Ω–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–∏
        growth_speed = re.search(r'–°–∫–æ—Ä–æ—Å—Ç—å —Ä–æ—Å—Ç–∞:?\s*([^\n]+)', career_text)
        transitions = re.search(r'–ü–µ—Ä–µ—Ö–æ–¥—ã:?\s*([^\n]+)', career_text)
        path_logic = re.search(r'–õ–æ–≥–∏–∫–∞ –ø—É—Ç–∏:?\s*([^\n]+)', career_text)
        progression = re.search(r'–ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è:?\s*([^\n]+)', career_text)
        achievements = re.findall(r'‚Ä¢\s*([^\n]+)', career_text)

        return {
            'growth_speed': growth_speed.group(1).strip() if growth_speed else '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
            'transitions': transitions.group(1).strip() if transitions else '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
            'path_logic': path_logic.group(1).strip() if path_logic else '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
            'progression': progression.group(1).strip() if progression else '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
            'achievements': [ach.strip() for ach in achievements] if achievements else []
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–∞—Ä—å–µ—Ä–µ: {e}")
        return {
            'growth_speed': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'transitions': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'path_logic': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'progression': '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ',
            'achievements': []
        }
